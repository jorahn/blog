<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Fine-Tuning PyTorch Vision Models | Blog by Jonathan Rahn</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Fine-Tuning PyTorch Vision Models" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Comparison of PyTorch CV Models on DeepFashion Dataset" />
<meta property="og:description" content="Comparison of PyTorch CV Models on DeepFashion Dataset" />
<link rel="canonical" href="https://jorahn.github.io/blog/vision/fine%20tuning/2021/09/06/PyTorch_Timm_Vision.html" />
<meta property="og:url" content="https://jorahn.github.io/blog/vision/fine%20tuning/2021/09/06/PyTorch_Timm_Vision.html" />
<meta property="og:site_name" content="Blog by Jonathan Rahn" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-09-06T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://jorahn.github.io/blog/vision/fine%20tuning/2021/09/06/PyTorch_Timm_Vision.html","@type":"BlogPosting","headline":"Fine-Tuning PyTorch Vision Models","dateModified":"2021-09-06T00:00:00-05:00","datePublished":"2021-09-06T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://jorahn.github.io/blog/vision/fine%20tuning/2021/09/06/PyTorch_Timm_Vision.html"},"description":"Comparison of PyTorch CV Models on DeepFashion Dataset","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://jorahn.github.io/blog/feed.xml" title="Blog by Jonathan Rahn" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script id="usercentrics-cmp" src="https://app.usercentrics.eu/browser-ui/latest/loader.js" data-settings-id="b0F7qzQbv" async></script>

<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-PHGTT9K');</script>
<!-- End Google Tag Manager -->


<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Blog by Jonathan Rahn</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Fine-Tuning PyTorch Vision Models</h1><p class="page-description">Comparison of PyTorch CV Models on DeepFashion Dataset</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-09-06T00:00:00-05:00" itemprop="datePublished">
        Sep 6, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#Vision">Vision</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Fine Tuning">Fine Tuning</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>After the surprising Image Classification results with <a href="/blog/clip/prompt%20engineering/2021/08/23/Zero_Shot.html">zero-shot CLIP</a>,
I’ve run a test over a number of deep computer vision architectures from <a href="https://github.com/pytorch/vision/tree/main/torchvision/models">torchvision</a>, 
<a href="https://github.com/fastai/fastai/blob/master/nbs/11_vision.models.xresnet.ipynb">fastai</a> and the awesome <a href="https://github.com/rwightman/pytorch-image-models">timm library</a> by Ross Wightman.</p>

<p>I’m using a 20-class subset of <a href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html">DeepFashion</a> with around 100k images
as the dataset. To accomodate memory requirements of different architectures, I’ve set batch_size to 32 (this leaves room for improvements
in smaller models). All models are pretrained on ImageNet, are built with a new initialized head and subsequently 
fine-tuned on DeepFashion for one epoch with frozen weights (new head only) and three epochs with unfrozen weights.</p>

<p><img src="/blog/images/finetuning_deepfashion/deepfashion.png" alt="image" title="DeepFashion Dataset" /></p>

<p>Training took on average ~20 minutes per epoch for all models on my hardware, so around 1:15h per model 
(the first epoch with frozen weights is generally a bit faster, than the others). The full run took around 18 hours in total.
Eventually, I might do a few more runs, just to get a feel for the actual distribution of results. Here are the results:</p>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Library</th>
      <th>Accuracy</th>
      <th>Training per epoch (mins)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>resnet34</td>
      <td>torch</td>
      <td>0.428767</td>
      <td>12:34</td>
    </tr>
    <tr>
      <td>resnet50</td>
      <td>torch</td>
      <td>0.441164</td>
      <td>18:08</td>
    </tr>
    <tr>
      <td>resnet101</td>
      <td>torch</td>
      <td>0.446995</td>
      <td>24:50</td>
    </tr>
    <tr>
      <td>resnet152</td>
      <td>torch</td>
      <td>0.448151</td>
      <td>32:15</td>
    </tr>
    <tr>
      <td>xresnet34</td>
      <td>fastai</td>
      <td>0.326014</td>
      <td>12:44</td>
    </tr>
    <tr>
      <td>xresnext34</td>
      <td>fastai</td>
      <td>0.255726</td>
      <td>15:24</td>
    </tr>
    <tr>
      <td>efficientnet_b0</td>
      <td>timm</td>
      <td>0.382433</td>
      <td>13:39</td>
    </tr>
    <tr>
      <td>efficientnet_b2</td>
      <td>timm</td>
      <td>0.385690</td>
      <td>16:47</td>
    </tr>
    <tr>
      <td>efficientnet_b4</td>
      <td>timm</td>
      <td>0.360475</td>
      <td>24:01</td>
    </tr>
    <tr>
      <td>densenet121</td>
      <td>timm</td>
      <td>0.395409</td>
      <td>20:14</td>
    </tr>
    <tr>
      <td>inception_v4</td>
      <td>timm</td>
      <td>0.395409</td>
      <td>23:00</td>
    </tr>
    <tr>
      <td>inception_resnet_v2</td>
      <td>timm</td>
      <td>0.405652</td>
      <td>25:18</td>
    </tr>
    <tr>
      <td>mobilenetv3_large_100</td>
      <td>timm</td>
      <td>0.385007</td>
      <td>11:40</td>
    </tr>
    <tr>
      <td>vit_base_patch16_224</td>
      <td>timm</td>
      <td>failed</td>
      <td>n/a</td>
    </tr>
    <tr>
      <td>xception41</td>
      <td>timm</td>
      <td>0.389262</td>
      <td>23:40</td>
    </tr>
  </tbody>
</table>

<p>I was a little surprised, how well the good-old ResNets perform in this setting. Even the smaller ones.
Certainly in terms of efficiency (cost/time to accuracy), they are a great choice.
I guess, it’s partly due to the training setup (dataset, hardware, batch size, epochs …),
that some models didn’t perform better. But for my use case, this was quite informative.</p>

<p><img src="/blog/images/finetuning_deepfashion/training_efficiency.png" alt="image" title="Normalized Training Efficiency" /></p>

<p>I’m investigating, why the timm-ViT model failed to run my benchmark and also, how to run the same
test with one of the pretrained CLIP vision models (ViT or ResNet).</p>

<p><em>Update:</em><br />
I’ve wanted to try <a href="https://wandb.ai/">Weights and Biases</a> for some time now, and this project has provided me 
with a great opportunity. After comparing architectures, I’ve run a couple of (parallel) experiments locally and in Colab
to compare ResNet34 with different Learning Rate Schedules on the same dataset. Please see 
<a href="https://wandb.ai/jrahn/finetune_resnet34_deepfashion/reports/DeepFashion-ResNet34-Fine-Tuning--VmlldzoxMDA0NTI1">here</a> for more details.</p>

<p><img src="/blog/images/finetuning_deepfashion/rn34_deepfashion_learning-rates.png" alt="image" title="Learning Rate Schedules with W&amp;B (showing 7 out of 10 runs)" /></p>

  </div><a class="u-url" href="/blog/vision/fine%20tuning/2021/09/06/PyTorch_Timm_Vision.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Mostly tech &amp; data notes.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/jorahn" title="jorahn"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/rahnjonathan" title="rahnjonathan"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
